# 인프런_딥러닝 강의

@섹션0~3.
- (hypothesis, cost function, gradient descent algo.)
- hupothesis = Wx + b // W, b 두개의 값을 학습
- cost(W,b) = 실제값과 예측한 값의 차이를 제곱하여 평균한 것(밥그릇 모양)
- 밥그릇 모양의 그래프에서 최적의 값을 찾기 위한 알고리즘 : gradient descent algorithm 

@섹션4. 여러개의 입력의 Linear Regression

- 이전까지는 하나의 인풋을 통해 학습했지만, 여러개의 input은 어떻게 해야할가?
- 하나의 input일땐 h=Wx+b, 3개의 입력일 경우 H(x1, x2, x3) = w1x1 + w2x2 + w3x3 + b
- cost function은 동일함
- 더 많은 경우(Multi-variable)의 경우도 위와 같이 동일한 형태를 띔

- 그러나 이를 잘 처리하기 위해 Matrix를 이용함. 행렬곱셈을 이용하면 쉽게 표현할 수 있음
- 1행3열의 행렬 (x1 x2 x3)와 3행1열의 행렬(w1 w2 w3)을 곱하면 (x1w1+x2w2+x3w3) 표현이 가능, H(X)=XW // x1w1 과 w1x1은 같으므로 순서 상관이 없음

- 인스턴스(x의 데이터 행 하나하나)가 많아도 동일함.
- 5개의 인스턴스인 x input 3개의 경우를 예를 들어보면, [5,3]행렬과 [3,1]행렬의 곱으로 [5,1] 5by1 결과가 도출됨.
- H(X)= XW,  X [5, 3] // 5개의 인스턴스 3개의 input
- [n,3] [3,1] = [n,1] // XW = H(X), 행렬의 곱셈 결과 형식을 이해해두자!
- ex) [n,3] [?,?] = [n,2]의 경우 곱셈결과 형식에 따라 3by2임을 알 수 있다.
-Lecture(theory)에서는 H(x) = Wx + b라면 텐서플로우에서는 H(X) = XW 형태로 구현된다. 수학적의미는 동일함을 알아두자.

@섹션5. Binary Classification
- 둘 중 하나의 결과를 도출시키는 classification
- 예시는 페이스북 피드 업로드, 스팸메일 처리, 신용카드 오사용 분류
- 이러한 예시를 컴퓨터로 쉽게 코드를 짤 수 있도록 encoding을 함, 0과 1로 구분짓는 것임. 스팸메일(1)_정상메일(0)
- 0과 1로 이루어진 결과만 도출하는 상황에서 linear regression으로 해결하는 것은 cost의 값이 매우 커지게 됨.
- 이유인즉 1이상의 값, 0이하의 값을 linear regression에서 도출되기 때문임
- 이 cost의 값을 낮추기 위한 그래프, 시그모이드(logistic fuction)라 함.
- H(x) = z = Wx+b, g(z) -> 0~1사이의 결과만 나오게 됨

- logistic function을 최소화 하기 위한 cost fuction.
- cost함수에 적용시 굽이친 그래프가 나오게 되며, local minimum을 global minimum을 찾지 못하게 하므로 y가 1인 상황과 0인 상황으로 나누며 로그 함수를 이용한 cost function을 적용함. 
- -log(H(x) : y=1 // -log(1-H(x)) : y=0
- 위 식을 하나의 식으로 통합할 수 있음.
- 텐서플로우에서 위 cost함수를 표현하고 gradientdescentoptimizer를 이용해서 적용하면 됨.

- tensorflow에서 데이터 읽기.
- numpy를 통해 대규모 다차원 배열을 쉽게 처리할 수 있게 해주는 파이썬 라이브러리 사용.
- import numpy as np
- np.loadtxt(csv 파일을 불러옴, 데이터를 나누는 기준, 데이터 타입)
- python Slicing : 시퀀스 자료구조의 특정 데이터를 잘라내는 것
- [:, 0:-1] 앞에 [ : ] 는 전체 행을 의미, [0:-1]은 0번 인덱스부터 -1번 인덱스까지 // -1은 마지막 원소 전까지
- [-1]이면 마지막 원소 이전것만 적용

- placeholder에서 shape=[None, 3] 코드를 볼 수 있다. none은 데이터 갯수를 초반에 모를 경우 이후에 임의로 바뀔 수 있다는 것임

- Queue Runners : 데이터가 커서 메모리에 올리기 힘든 경우 Queue Runners를 사용함. 여러 파일을 큐에 쌓아 놓고 reader로 파일을 읽어옴
- 과정 : 1. 파일 이름을 리스트로 생성 2. 파일 읽어올 리더 선언, 연결 3. value 파싱 설정(디코딩)

@ 세션6. Softmax Regression
- logistic regression 복습
- H(x) = Wx의 결과가 1을 초과한 큰 값이 나오므로 이를 z로 생각하고, g(z)라는 수식이 큰 값들을 0과 1사이로 압축해줌. 
- x -> w -> z -> y의 햇 // z를 통해 시그모이드로 변환, y햇은 0과 1사이
- 2개의 결과를 구분 짓은 리니어를 그리는 것.

- multinomial classification ( 여러개의 입력을 통한 여러개의 결과 )
- binary classification으로 multinomial classification 구현이 가능함.
- ex) a, b, c가 있는 경우 a b / c - c or not, b / a c - b or not, a / b c - a or not
- y --s(y)--> p(모두 합하면 1, 확률) <-one-hot enncoding-> 하나의 유력한 값이 1로 변함. 
- cross-entropy cost function, 결과를 예측하기 위해 위 수식에 대입하여 0이 나오면 cost가 0이므로 결과가 적중한다는 의미임. 
- Cross-entropy VS Logistic cost
- Gradient descent 똑같이 적용.

- tensorflow에 적용.
- hypothesis = tf.nn.softmax(tf.matmul(X,W)+b)
- Cost function : cross entropy
- cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(hypothesis), axis=1))
- optimizer = tf.train.GradientDescentOptimizer(learning_rata=0.1).minimize(cost)





@ 세션7 Learning rate, Evaluation
- learning rate를 잘못 설정할 경우.
- test data를 통해 모델을 다시 한번 재 평가하여 확인해주어야 함.
- training과 test datasets을 나누어야 함. 모델의 정확도를 파악해야 하기 때문임
- training : 모델에 학습되는 데이터 / test datasets : 모델이 한번도 보지 못한 데이터

- learning rate가 너무 크면, 움직이는 폭이 커서 밖으로 튀어나가는 overshooting이 발생할 수 있음
- learning rate가 너무 작으면 학습이 너무 느려서 진행이 안될 수 있으며, 작은 굴곡이 존재하면 그 안에서 갇히는 문제가 발생 - local minima 현상
- 이 문제를 normalization 정규화를 통해 0~1사이의 값을 매겨주는 일반화 과정을 거침.
- 데이터 크기가 들쭉날쭉할때는 일반화 과정을 하는 것이 좋음
- overfitting 문제 : 너무 데이터에 집착(너무 line을 구부리는)하여 타 모델에 직접 적용되었을 경우 일반적인 결과를 내지 못할 수 있음.
- 이를 해결하기 위해 더 많은 트레이닝 데이터, 갖고 있는 feature의 갯수를 줄이거나 Regularization(일반화)를 거침.
- regularization은 각 요소들을 제곱하여 더한 것에 regularization strength를 곱한 것을 loss 함수에 더하면 됨.



- MNIST Dataset : 우편번호를 자동으로 읽을 수 있도록 만듬

@ 섹션8. 딥러닝의 기본개념: 시작과 XOR문제
- Deep Neural Network.
- 궁극적인 목적 : 인간의 생각을 대신 해주는 것.
- 인간의 생각의 주체 -> 뇌, 뇌의 구성을 연구 -> 뉴런 (다소 단순한)
- 뉴런 : 시냅스로 부터 input, 이 자체를 X*W로 볼 수 있음.

- AND/OR등을 기계가 푼다면 되지 않을까 라는 과거의 생각.
- 그러나 XOR을 풀지 못하였음.
- Minsky가 XOR문제를 풀지 못할 것이라는 증명을 냄
- 이유인즉, Multi layer(MLP)에서 학습하는 문제가 어렵기 떄문.

- 이후 Paul의 Backpropagation으로 이 문제를 풀 수 있게 되었음.
- 그러나, 다시 한번 Backpropagation으로 해결하지 못하는, 여러개의 Deep한 layer가 있어 성능이 저하하게 됨(Deep하므로 전달이 제대로 되지 않아서)
- 차라리 SVM, Random forest로 더 좋은 결과를 낳을 수 있음. -> 제2침체기
- 이후 CIFAR 캐나다 단체에서 적극적으로 지원함. 

- 2006, 2007년. Hinton, Bengio가 논문을 발표.
- Deep한 layer에 초기값을 잘 줄 수 있는 방도에 대한 논문. (신경망 구축)
- 즉, 어려운 문제를 풀 수 있게 됨. 이러한 것을 대중성을 얻기 위해 Deep Learning이라고 이름 부침.

- 계속해서 딥러닝 분야는 발전하고 있음. 예시로 IMAGENET은 2012년 급격하게 높은 오류율을 큰 격차로 떨어트리게 됨.(26.2%->15.3%)
- 2015년에 다다르게 되어서는 인간은 5%의 오류를 얻는데에 비해 기계는 3%의 오류를 얻게 됨.
- IMAGENET은 이미지 구분 연구
- 이전까지의 실패와 침체기에 대한 Hinton이 밝힌 4가지 이유 -> Cs231n 강좌 참고


- shape, rank, rank는 [의 갯수를 볼것. shape는 안부터 파악.
- Axis(축 개념) : 가장 바깥 -1,  안으로 들어갈수록 up
- BroadCast : shape가 달라도 연산, 격을 맞춰주는 역할을 함. 그러나 가급적 같은 shape로 계산할 것.
- Argmax : 가장 큰 값의 위치
- reduce_mean, reduce_sum : 이또한 축과 같이 사용할 수 있음.

- Reshape : 가급적 안 shape는 조정하지 말 것. shape모양을 조정해주는
- Reshape squeeze : 쫙 펴주는, expand_dims : 선택한 숫자로 shape 변경
- one-hot : 선택된 자리를 1로 바꾸어 주는 // tf.one_hot
- casting : true, false를 1과 0으로 cast하거나 소수를 int형으로 바꾸어주는 식의 cast 변환 // tf.cast
- stack : tf.stack
- ones and zeros like : 0이나 1로 똑같은 모양을 만들어주는
- Zip : 복수의 tensor를 zip으로 묶어 한 번에 해결하는 역할이 가능. 

@ 섹션9. Neural Nets for XOR, backpropagation
- XOR문제는 하나의 선, One logistic regression으로 해결이 불가
- Multiple logistic regression으로 가능.
- 여러개의 unit으로 겹칠 경우 해결이 가능하나, 각각의 복잡한 네트워크에서 W와 b를 학습하는 것이 불가.

- 자동으로 W와 b를 학습할 수 있는 backpropagation이 등장.
- 예상값과 실제 출력의 차이(오류)를 갖고 뒤에서 앞으로 돌리면서 미분값을 어떻게 조정해야 하는지 알게 해주는 알고리즘.
- Gradient Descent Algorithm을 사용하여 Global minimum에 도달하기까지 어떠한 점에서 미분값이 필요. 

- f를 w로 미분하는 것은 (f를 g로 편미분) * (g를 w로 편미분)으로 표현이 가능.
- 이것이 Chain Rule이며, back propagation또한 이 chain rule을 이용하여 복잡한 내부 유닛들의 미분값을 쉽게 구할 수 있음.
- 이를 통해 미분값(영향도)를 얻게 되며, 미분값이 나타내는 바는 식의 변화도의 비율을 나타내는 것임.
- 실제로 back propagation은 텐서플로우에서 텐서보드가 이를 계산하므로 직접 chain rule을 통해 체크할 필요가 없음.

- L2 regularization
- overfitting은 trainning data에만 지나치게 적응하여 test data에 제대로 반응하지 못하는 현상이다.
- 여기서 L2 regularization은 가장 일반적으로 사용되는 일반화 기법으로, overfitting은 가중치 매개변수의 값이 커서 발생하는 경우가 가중치가 클수록 패널티를 부과하여 overfitting을 억제함.






